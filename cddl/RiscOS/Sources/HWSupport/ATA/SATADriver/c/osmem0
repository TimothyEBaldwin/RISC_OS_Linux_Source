/*
 * CDDL HEADER START
 *
 * The contents of this file are subject to the terms of the
 * Common Development and Distribution License (the "Licence").
 * You may not use this file except in compliance with the Licence.
 *
 * You can obtain a copy of the licence at
 * cddl/RiscOS/Sources/HWSupport/ATA/SATADriver/LICENCE.
 * See the Licence for the specific language governing permissions
 * and limitations under the Licence.
 *
 * When distributing Covered Code, include this CDDL HEADER in each
 * file and include the Licence file. If applicable, add the
 * following below this CDDL HEADER, with the fields enclosed by
 * brackets "[]" replaced with your own identifying information:
 * Portions Copyright [yyyy] [name of copyright owner]
 *
 * CDDL HEADER END
 */
/*
 * Copyright 2015 Ben Avison.  All rights reserved.
 * Portions Copyright 2017 Jeffrey Lee
 * Use is subject to license terms.
 */

#include <string.h>
#include "kernel.h"
#include "swis.h"

#include "Global/NewErrors.h"

#include "globals.h"
#include "dmaprep.h"
#include "message.h"

#define PAGE_SIZE 4096

/* Circular dependencies requires pre-declaration of the following: */
static _kernel_oserror *for_scatter_list(ahciop_t *op, size_t limit, _kernel_oserror *(*callback)(ahciop_t *, size_t, size_t *, void *), void *context);

static _kernel_oserror *mark_uncacheable(void *log, paddr_t *phys)
{
  uint32_t buffer[3];
  buffer[1] = (uintptr_t) log;
  _kernel_oserror *e = _swix(OS_Memory, _INR(0,2), (1u<<9) | (1u<<13) | (2u<<14), buffer, 1);
  *phys = (paddr_t) buffer[2];
  return e;
}

static void mark_cacheable(void *log)
{
  uint32_t buffer[3];
  buffer[1] = (uintptr_t) log;
  _swix(OS_Memory, _INR(0,2), (1u<<9) | (3u<<14), buffer, 1);
}

static _kernel_oserror *postprocess_bounce(ahciop_t *restrict op, size_t byte_index, size_t *restrict advance_by, void *context)
{
  /* A bounced operation has completed */
  /* Assume we're only called in the read case - nothing to do otherwise */
  uint8_t *bounce_buffer = context;
  memcpy(op->list->address, bounce_buffer + byte_index, *advance_by);
  return NULL;
}

static _kernel_oserror *preprocess_bounce(ahciop_t *restrict op, size_t byte_index, size_t *restrict advance_by, void *context)
{
  /* A bounced operation has completed */
  /* Assume we're only called in the write case - nothing to do otherwise */
  uint8_t *bounce_buffer = context;
  memcpy(bounce_buffer + byte_index, op->list->address, *advance_by);
  return NULL;
}

static _kernel_oserror *postprocess_direct(ahciop_t *restrict op, size_t byte_index, size_t *restrict advance_by, void *context)
{
  /* We've finished a direct operation (or it never started) so restore page state */
  (void) byte_index;
  (void) context;
  size_t bytes_to_page_boundary = PAGE_SIZE - (((uintptr_t) op->list->address + op->scatter_offset) & (PAGE_SIZE - 1));
  *advance_by = MIN(*advance_by, bytes_to_page_boundary);
  mark_cacheable(op->list->address + op->scatter_offset);
  return NULL;
}

typedef struct
{
  ahci_prdt_entry_t *prdt_entry;
  ataop_block_t     *b;
  scatter_t         *list_start;
}
preprocess_direct_context_t;

/** Magic error pointer used to halt iteration through a scatter list once we've
 *  determined that we have to use a bounce buffer */
#define ESCAPE_FROM_SCATTER_LIST_ITERATOR ((_kernel_oserror *) 1)

static _kernel_oserror *preprocess_direct(ahciop_t *restrict op, size_t byte_index, size_t *restrict advance_by, void *context)
{
  _kernel_oserror *e = NULL;
  ahci_prdt_entry_t *p;
  size_t bytes_to_page_boundary;
  paddr_t paddr;

  if (((uintptr_t) op->list->address & 1) != 0 ||
      (*advance_by & 1) != 0)
  {
    /* DMA system can only cope with 16-bit transfers of an even number of bytes */
    goto failed;
  }

  /* Mark pages as temporarily uncached and build the PRDT at the same time */
  p = ((preprocess_direct_context_t *)context)->prdt_entry;
  bytes_to_page_boundary = PAGE_SIZE - (((uintptr_t) op->list->address + op->scatter_offset) & (PAGE_SIZE - 1));
  *advance_by = MIN(*advance_by, bytes_to_page_boundary);
  if ((e = mark_uncacheable(op->list->address + op->scatter_offset, &paddr)) != NULL)
  {
    /* Considering FileSwitch has already validated the addresses, the most
     * likely reason for OS_Memory 0 to have failed is that the memory block
     * is ROM or IO (e.g. screen buffers on some platforms). We have to handle
     * these using the bounce buffer, just as for unaligned RAM transfers.
     * Some earlier scatter list entries may have been OK, so we'll have to
     * restore their cacheability before returning even for error-free case */
    goto failed;
  }
  /* Look to see if we can merge this into the previous PRDT entry */
  if (p != op->prdt &&
      paddr == (paddr_t) p[-1].dba + p[-1].dbc + 1 &&
      *advance_by < AHCI_DBC_MAX - (p[-1].dbc + 1))
  {
    p[-1].dbc += *advance_by;
    return NULL;
  }
  /* Check for PRDT overflow */
  if (p == op->prdt + AHCI_MAX_PRDT_ENTRIES)
  {
    goto failed;
  }
  /* Extend PRDT by one entry */
  p->dba = paddr;
  p->dbc = *advance_by - 1;
  ((preprocess_direct_context_t *)context)->prdt_entry = ++p;
  return NULL;

failed:
  /* Unless the transfer is already for 4K or less, we'll need the caller to
   * truncate the transfer to the next-smallest multiple of 4K (to achieve a
   * wholly aligned transfer to/from RAM) or to 4K (to achieve an unaligned/ROM/IO
   * transfer that uses the bounce buffer only once). It has to be the caller's
   * responsibility to do this because we don't understand the contents of the
   * parameter block at this level. */
  if (op->total_length <= BOUNCE_BUFFER_SIZE)
  {
    op->use_bounce_buffer = true;
    e = ESCAPE_FROM_SCATTER_LIST_ITERATOR;
  }
  else
  {
    ataop_block_t *b = ((preprocess_direct_context_t *)context)->b;
    b->data_len = byte_index &~ (BOUNCE_BUFFER_SIZE - 1);
    if (b->data_len == 0)
      b->data_len = BOUNCE_BUFFER_SIZE;
    e = MESSAGE_ERRORLOOKUP(true, TooComplex, 0);
  }
  /* Need to undo any cacheability changes up to this point */
  op->list = ((preprocess_direct_context_t *)context)->list_start;
  for_scatter_list(op, byte_index, postprocess_direct, NULL);
  return e;
}

static void advance_scatter_pointer(ahciop_t *op)
{
  do
  {
    if (op->list->length == 0 && (uintptr_t) op->list->address >= SCATTER_THRESHOLD)
      op->list = (scatter_t *) ((uintptr_t) op->list + (uintptr_t) op->list->address);
    else
      op->list++;
    op->scatter_offset = 0;
  }
  while (op->scatter_offset >= op->list->length);
}

static _kernel_oserror *for_scatter_list(ahciop_t *op, size_t limit, _kernel_oserror *(*callback)(ahciop_t *, size_t, size_t *, void *), void *context)
{
  _kernel_oserror *e = NULL;
  size_t byte_index = 0;
  size_t advance_by;
  scatter_t *list_start = op->list; // so we can restore it on exit
  op->scatter_offset = 0;
  while (byte_index < limit)
  {
    if (op->scatter_offset >= op->list->length)
      advance_scatter_pointer(op);
    advance_by = MIN(op->list->length - op->scatter_offset, limit - byte_index);
    if ((e = callback(op, byte_index, &advance_by, context)) != NULL)
    {
      op->list = list_start;
      return e;
    }
    op->scatter_offset += advance_by;
    byte_index += advance_by;
  }
  op->list = list_start;
  return NULL;
}

dmaprep_result_t dmaprep_prep(ahciop_t *op, ataop_block_t *b, scatter_t *scat, ahciport_t *port)
{
  dmaprep_result_t res = {0};

  op->use_bounce_buffer = false; // until we determine otherwise
  op->list = scat;

  if (op->total_length > 0)
  {
    /* Check to see whether the transfer can be achieved or if it needs to be
     * truncated. If it can be achieved, determine whether we need to use the
     * bounce buffer or not. If not using the bounce buffer, mark pages as
     * temporarily uncacheable and build the PRDT. */
    preprocess_direct_context_t context = { op->prdt, b, op->list };
    res.e = for_scatter_list(op, op->total_length, preprocess_direct, &context);

    /* By now we know for sure whether we're using the bounce buffer or not */
    if (op->use_bounce_buffer) // implies that the transfer doesn't need truncating
    {
      op->prdt[0].dba = port->bounce_buffer_phy;
      op->prdt[0].dbc = (op->total_length - 1) | AHCI_DBC_I;
      res.e = NULL;
      res.prdt_len = 1;
    }
    else if (res.e == NULL)
    {
      context.prdt_entry[-1].dbc |= AHCI_DBC_I;
      res.prdt_len = context.prdt_entry - op->prdt;
    }
  }
  return res;
}

void dmaprep_on_queue(ahciop_t *op, ahciport_t *port)
{
  if (op->use_bounce_buffer && (op->description_info & COMMANDHDR_W) != 0)
    for_scatter_list(op, op->total_length, preprocess_bounce, port->bounce_buffer); /* can't error */
  memcpy(&port->command_table->prdt, &op->prdt,
      sizeof (ahci_prdt_entry_t) * ((op->description_info & COMMANDHDR_PRDTL_MASK) >> COMMANDHDR_PRDTL_SHIFT));
}

void dmaprep_on_abort(ahciop_t *op)
{
  if (!op->use_bounce_buffer)
    for_scatter_list(op, op->total_length, postprocess_direct, NULL);
}

void dmaprep_on_complete(ahciop_t *op, ahciport_t *port)
{
  if (op->use_bounce_buffer && (op->description_info & COMMANDHDR_W) == 0)
    for_scatter_list(op, op->length_done, postprocess_bounce, port->bounce_buffer); /* can't error */
  else if (!op->use_bounce_buffer)
    for_scatter_list(op, op->length_done + op->total_length, postprocess_direct, NULL);
}
