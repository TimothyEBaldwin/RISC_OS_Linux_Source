; Copyright 2022 RISC OS Open Ltd
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;

; Assumptions:
; * Single-core machine (no barriers)
; * Needs to be atomic with interrupt handlers: Atomic reads & writes are fine, but non-atomic ones require IRQs disabling
; * Halfword load/store support

; We only deal with halfword ops here
size    SETA    2
sz      SETS    "H"
sz2     SETS    (:STR:size) :RIGHT: 1

; void _kernel_atomic_store_N(volatile void* obj, memory_order order, C desired);
      [ :DEF: Need__kernel_atomic_store_$sz2._Halfword
        FUNC    _kernel_atomic_store,,_Halfword
        STR$sz  a3, [a1]
        Return  ,LinkNotStacked
      ]

; C _kernel_atomic_load_N(volatile void* obj, memory_order order);
      [ :DEF: Need__kernel_atomic_load_$sz2._Halfword
        FUNC    _kernel_atomic_load,,_Halfword
        LDR$sz  a1, [a1]
        Return  ,LinkNotStacked
      ]

; C _kernel_atomic_exchange_N(volatile void* obj, memory_order order, C desired);
      [ :DEF: Need__kernel_atomic_exchange_$sz2._Halfword
        FUNC    _kernel_atomic_exchange,,_Halfword
        FunctionEntry
        SpinLock_IRQ a2, lr
        LDR$sz  a4, [a1]
        STR$sz  a3, [a1]
        SpinUnlock_IRQ a2, lr
        MOV     a1, a4
        Return
      ]

; _Bool _kernel_atomic_compare_exchange_weak_N(volatile void* obj, int orders, C* expected, C desired);
; _Bool _kernel_atomic_compare_exchange_strong_N(volatile void* obj, int orders, C* expected, C desired);
      [ :DEF: Need__kernel_atomic_compare_exchange_weak_$sz2._Halfword :LOR: :DEF: Need__kernel_atomic_compare_exchange_strong_$sz2._Halfword
        FUNC    _kernel_atomic_compare_exchange_weak,,_Halfword
        FUNC    _kernel_atomic_compare_exchange_strong,,_Halfword
        FunctionEntry
        LDR$sz  ip, [a3]
        SpinLock_IRQ a2, lr
        LDR$sz  lr, [a1]
        TEQ     lr, ip
        STREQ$sz a4, [a1]
        STRNE$sz lr, [a3]
        MOVEQ   a1, #1
        MOVNE   a1, #0
        SpinUnlock_IRQ a2, lr
        Return
      ]

; C _kernel_atomic_fetch_add_N(volatile void* obj, memory_order order, M arg);
      [ :DEF: Need__kernel_atomic_fetch_add_$sz2._Halfword
        FUNC    _kernel_atomic_fetch_add,,_Halfword
        FunctionEntry
        MOV     ip, a1
        SpinLock_IRQ a2, lr
        LDR$sz  a1, [ip]
        ADD     a3, a1, a3
        STR$sz  a3, [ip]
        SpinUnlock_IRQ a2, lr
        Return
      ]

; fetch_xor, fetch_or, fetch_and are implemented using a routine which performs
; an AND & XOR pair. This helps cut down the number of routines needed, without
; slowing things down too much.

; C _kernel_atomic_fetch_xor_N(volatile void* obj, memory_order order, M arg);
      [ :DEF: Need__kernel_atomic_fetch_xor_$sz2._Halfword
        FUNC    _kernel_atomic_fetch_xor,,_Halfword
        FunctionEntry "v1"
        MVN     v1, #0
        B       andxor_Halfword
      ]

; C _kernel_atomic_fetch_or_N(volatile void* obj, memory_order order, M arg);
      [ :DEF: Need__kernel_atomic_fetch_or_$sz2._Halfword
        FUNC    _kernel_atomic_fetch_or,,_Halfword
        FunctionEntry "v1"
        MVN     v1, a3
        B       andxor_Halfword
      ]

; C _kernel_atomic_fetch_and_N(volatile void* obj, memory_order order, M arg);
      [ :DEF: Need__kernel_atomic_fetch_and_$sz2._Halfword
        FUNC    _kernel_atomic_fetch_and,,_Halfword
        FunctionEntry "v1"
        MOV     v1, a3
        MOV     a3, #0
        B       andxor_Halfword
      ]

      [ :DEF: Need__kernel_atomic_fetch_xor_$sz2._Halfword :LOR: :DEF: Need__kernel_atomic_fetch_or_$sz2._Halfword :LOR: :DEF: Need__kernel_atomic_fetch_and_$sz2._Halfword
andxor_Halfword
        MOV     ip, a1
        SpinLock_IRQ a2, lr
        LDR$sz  a1, [ip]
        AND     v1, a1, v1
        EOR     a3, a3, v1
        STR$sz  a3, [ip]
        SpinUnlock_IRQ a2, lr
        Return  "v1"
      ]

        LTORG

        END
