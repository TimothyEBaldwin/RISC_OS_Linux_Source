;
; Copyright (c) 2013, 2017, Timothy Baldwin
;
; Licensed under the Apache License, Version 2.0 (the "License");
; you may not use this file except in compliance with the License.
; You may obtain a copy of the License at
;
;     http://www.apache.org/licenses/LICENSE-2.0
;
; Unless required by applicable law or agreed to in writing, software
; distributed under the License is distributed on an "AS IS" BASIS,
; WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
; See the License for the specific language governing permissions and
; limitations under the License.
;

        GET     Hdr:ListOpts
        GET     Hdr:Macros
        GET     Hdr:System
        GET     Hdr:Machine.<Machine>
        GET     Hdr:HALSize.<HALSize>
        GET     Hdr:HALDevice
        GET     Hdr:OSEntries
        GET     Hdr:LinuxSyscalls
        GET     Hdr:LinuxDefs

        IMPORT  __PVirt_PatchCode
        EXPORT  __PVirt_SWI
        EXPORT  __PVirt_FastSWI

        IMPORT  __PVirt_LinuxSyscall

        EXPORT  __PVirt_GetCPSR
        EXPORT  __PVirt_GetDFAR
        EXPORT  __PVirt_GetSPSR
        EXPORT  __PVirt_LoadSaveBlock
        EXPORT  __PVirt_LoadUsr
        EXPORT  __PVirt_LoadUsrRegisters
        EXPORT  __PVirt_MOVS_PC_LR
        EXPORT  __PVirt_SetCPSR_c
        EXPORT  __PVirt_SetCPSR_cxsf
        EXPORT  __PVirt_SetCPSR_c_unstack
        EXPORT  __PVirt_SetCPSR_cf_unstack
        EXPORT  __PVirt_SetCPSR_cs_unstack
        EXPORT  __PVirt_SetCPSR_csf_unstack
        EXPORT  __PVirt_SetCPSR_cx_unstack
        EXPORT  __PVirt_SetCPSR_cxf_unstack
        EXPORT  __PVirt_SetCPSR_cxs_unstack
        EXPORT  __PVirt_SetCPSR_cxsf_unstack
        EXPORT  __PVirt_SetSPSR
        EXPORT  __PVirt_StoreUsr

        EXPORT  __PVirt_FindMode
        EXPORT  __PVirt_GetVCPU
        EXPORT  __PVirt_VModeOffsets

        EXPORT  SetCPSR_End
        EXPORT  SetCPSR_Restart
        EXPORT  SetCPSR_Start
        EXPORT  HAL_InitDevices
        EXPORT  Device_PSR

        EXPORT  fast_signal_exit
        EXPORT  fast_signal_exit2

        EXPORT  SWI_handler
        EXPORT  call_irq
        EXPORT  init_vcpu
        EXPORT  test_stack
        IMPORT  test_vectors
        IMPORT  image_start
        IMPORT  __HAL_get_env

PVirt   SETA    PVSys

        AREA    ASM, CODE, READONLY

__PVirt_GetCPSR
        STR     lr, [sp, #-4]!
        BL      __PVirt_GetVCPU
        LDRB    lr, [r0, #vcpu_cpsr]
        MRS     r0, CPSR
        BIC     r0, r0, #0xFF ; ARMv7 says the privileged bits are UNKNOWN.
        ORR     r0, r0, lr
        LDR     pc, [sp], #4

__PVirt_FindMode
        STR     lr, [sp, #-4]!
        BL      __PVirt_GetVCPU
        LDRB    lr, [r0, #vcpu_cpsr]
        AND     lr, lr, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        ADD     r0, r0, lr
        LDR     pc, [sp], #4

__PVirt_SetSPSR
        STMFD   sp!, {r0, lr}
        BL      __PVirt_FindMode
        STR     r1, [r0, #8]
        LDMFD   sp!, {r0, pc}

__PVirt_GetSPSR
        STR     lr, [sp, #-4]!
        BL      __PVirt_FindMode
        LDR     r0, [r0, #8]
        LDR     pc, [sp], #4

__PVirt_GetDFAR
        STR     lr, [sp, #-4]!
        BL      __PVirt_GetVCPU
        LDR     r0, [r0, #vcpu_DFAR]
        LDR     pc, [sp], #4

__PVirt_GetVCPU
        LDR     pc, =0xFFFF0FE0

__PVirt_StoreUsr
        STMFD   sp!, {r0, r2, lr}
        BL      __PVirt_GetVCPU
        LDR     r2, [r0, #vcpu_r13_usr]
        LDR     lr, [r0, #vcpu_r14_usr]
        STMIA   r1, {r2, lr}
        LDMFD   sp!, {r0, r2, lr}
        myBX    lr

__PVirt_LoadUsr
        STMFD   sp!, {r0, r2, lr}
        BL      __PVirt_GetVCPU
        LDMIA   r1, {r2, lr}
        STR     r2, [r0, #vcpu_r13_usr]
        STR     lr, [r0, #vcpu_r14_usr]
        LDMFD   sp!, {r0, r2, lr}
        myBX    lr

SetCPSR_Start

fast_signal_exit
        MSR     cpsr_sf, r1
fast_signal_exit2
        LDR     r2, [r0, #15*4]
        LDR     lr, [r0, #14*4]
        STR     r2, [r0, #14*4]
        LDMIA   r0, {r0-r13, pc}
SWI_handler
        ; r1 = pointer to struct siginfo
        ; r2 = pointer to struct ucontext
        ;
        ; Values are safe until sp is loaded

        CallI   =0xFFFF0FE0
        LDRB    r6, [r0, #vcpu_cpsr]
        AND     lr, r6, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        ADD     lr, lr, r0

        ADD     r3, r2, #ix_struct_ucontext_registers + 12 * 4
        LDMIA   r3, {r2, r4, r5, r7, r8}
        STMIA   lr, {r4, r5}

        BIC     r8, r8, #0xDF
        ORR     r8, r8, r6
        STR     r8, [r0, #vcpu_spsr_svc]

        LDR     lr,  [r1, #12] ; si_call_addr
        LDR     r12, [r0, #vcpu_r13_svc]

        ; Save CPSR
        MOV     r1, #SVC32_mode + I32_bit
        STRB    r1, [r0, #vcpu_cpsr]

        ; Return PC = SVC vector
        LDR     r1, [r0, #vcpu_vectors]
        LDR     r4, [r1, #4]
        STMFD   r12!, {r2, r4}

        ; Load registers
        SUB     r3, r3, #12 * 4
        LDMIA   r3, {r0-r11}
        MOV     sp, r12
        LDMFD   sp!, {r12, pc}

__PVirt_FastSWI
        STMDB   sp!, {r0-r3, lr}
__PVirt_SWI
        ADD     r1, sp, #5*4  ; R1 = caller SP
        LDR     r2, [r1, #-4] ; R2 = caller LR
        ADD     r3, lr, #4
        BL      __PVirt_GetVCPU

        ; Save LR and SP
        LDRB    lr, [r0, #vcpu_cpsr]
        AND     lr, lr, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        ADD     lr, r0, lr
        STMIA   lr, {r1-r2}

        ; Save SPSR
        LDRB    lr, [r0, #vcpu_cpsr]
        MRS     r2, CPSR
        BIC     r2, r2, #0xFF ; ARMv7 says the privileged bits are UNKNOWN.
        ORR     r2, r2, lr
        STR     r2, [r0, #vcpu_spsr_svc]

        ; Save CPSR
        MOV     r2, #SVC32_mode + I32_bit
        STRB    r2, [r0, #vcpu_cpsr]

        ; Return PC = SVC vector
        LDR     r2, [r0, #vcpu_vectors]
        LDR     r2, [r2, #4]
        STR     r2, [r1, #-4]

        ; Load LR and SP
        LDR     sp, [r0, #vcpu_r13_svc]
        MOV     lr, r3

        LDMDB   r1, {r0-r3, pc}

__PVirt_LoadSaveBlock
        MOV     r2, sp
        LDR     r3, [r1, #16*4]
__PVirt_LoadUsrRegisters
        ; r1 = pointer to new values of r0-r12,r13_usr,r14_usr,pc
        ; r2 = new calling mode sp
        ; r3 = new CPSR
        MOV     r9, lr
        BL      __PVirt_GetVCPU
        LDRB    r4, [r0, #vcpu_cpsr]
        AND     r4, r4, #M32_bits
        ADD     r4, r4, #__PVirt_VModeOffsets - . - 12
        LDRB    r4, [pc, r4]
        STR     r2, [r4, r0]! ; Save calling SP
        STR     r9, [r4, #4]  ; Save calling LR

        ADD     r4, r1, #12*4
        LDMIA   r4, {r5, r6, r7, r8}
        STR     r6, [r0, #vcpu_r13_usr]
        STR     r7, [r0, #vcpu_r14_usr]
        MOV     r2, sp
        STMFD   sp!, {r5, r8}

        LDMIA   r1!, {r5, r6, r7, r8}
        STMFD   sp!, {r5, r6, r7, r8}

        LDMIA   r1, {r4-r11}

        AND     ip, r3, #M32_bits
        ADD     ip, ip, #__PVirt_VModeOffsets - . - 12
        LDRB    ip, [pc, ip]
        LDR     sp, [ip, r0]!
        LDR     lr, [ip, #4]

        STRB    r3, [r0, #vcpu_cpsr]
        MOV     r1, r3
        B       SetCPSR_Restart

enter_irq
        MOV     ip, #IRQ32_mode + I32_bit
        STRB    ip, [r0, #vcpu_cpsr]

        AND     r1, r1, #0xFF
        BIC     lr, r3, #0xFF
        ORR     lr, r1, lr ; r3 = Return CPSR
        STR     lr, [r0, #vcpu_spsr_irq]

        LDR     lr, [r2, #-4] ; lr = Return PC
        ADD     lr, lr, #4
        LDR     sp, [r0, #vcpu_r13_irq]

        LDR     r1, [r0, #vcpu_vectors]
        LDR     r1, [r1, #5*4]
        STR     r1, [r2, #-4] ; Return PC = IRQ vector

        MSR     CPSR_sf, r3
        LDMDB   r2, {r0-r3, ip, pc}


__PVirt_SetCPSR_cf_unstack
__PVirt_SetCPSR_cxf_unstack
        MSR     CPSR_f, r1
        B       __PVirt_SetCPSR_c_unstack

__PVirt_SetCPSR_cs_unstack
__PVirt_SetCPSR_cxs_unstack
        MSR     CPSR_s, r1
        B       __PVirt_SetCPSR_c_unstack

__PVirt_MOVS_PC_LR
        STMFD   sp!, {r0-r3, ip, lr}
        BL      __PVirt_GetVCPU
        LDR     lr, [sp, #5*4]  ; Restore callers LR

        LDRB    r2, [r0, #vcpu_cpsr]
        AND     ip, r2, #M32_bits
        ADR     r2, __PVirt_VModeOffsets

        LDRB    ip, [r2, ip]
        ADD     sp, sp, #6*4
        STR     sp, [ip, r0]!   ; ip is now pointer to calling mode r13 and r14 save area

        LDR     r1, [ip, #8]
        MOV     r3, r1
        B       SetCPSR_MOVS_PC_LR

__PVirt_SetCPSR_csf_unstack
__PVirt_SetCPSR_cxsf_unstack
        MSR     CPSR_sf, r1
__PVirt_SetCPSR_c_unstack
__PVirt_SetCPSR_cx_unstack
        ;   In: r1 = new CPSR_c value
        ;       lr = return address
        ;       sp = stack from STMFD sp!, {r0-r3, ip, lr}
        ;
        ; Temp: r0 = Pointer to vcpu struct
        ;       r2 = SP on entry
        ;       r3 = saved CPSR_sf value
        ;       ip = temp register

        MRS     r3, CPSR
        ADD     ip, lr, #4      ; Adjust return address to avoid MSR CPSR_c
        BL      __PVirt_GetVCPU
        LDR     lr, [sp, #5*4]  ; Read callers LR
        STR     ip, [sp, #5*4]  ; Put old PC in it's place


        LDRB    r2, [r0, #vcpu_cpsr]
        AND     ip, r2, #M32_bits
        TEQ     ip, #USR32_mode
        MOVEQ   r1, r2 ; In USR mode, so do nothing

        ADR     r2, __PVirt_VModeOffsets

        LDRB    ip, [r2, ip]
        ADD     sp, sp, #6*4
        STR     sp, [ip, r0]!
SetCPSR_MOVS_PC_LR
        STR     lr, [ip, #4]

        AND     ip, r1, #M32_bits
        LDRB    ip, [r2, ip]
        MOV     r2, sp
SetCPSR_tail
        LDR     sp, [ip, r0]!
        LDR     lr, [ip, #4]
        STRB    r1, [r0, #vcpu_cpsr]

SetCPSR_Restart
        LDRB    ip, [r0, #vcpu_irq_pending]
        BICS    ip, ip, r1
        BNE     enter_irq
        TST     r1, #E32_bit | T32_bit
        STRNE   r0, [r0, -r0]   ; fix this up in signal handler
        MSR     CPSR_sf, r3
        LDMDB   r2, {r0-r3, ip, pc}
SetCPSR_End

__PVirt_SetCPSR_cxsf
        MSR     CPSR_sf, r1
__PVirt_SetCPSR_c
        MOV     ip, lr
        MRS     r3, CPSR
        BL      __PVirt_GetVCPU
        LDRB    lr, [r0, #vcpu_cpsr]
        MOV     r2, #255
        STRB    r2, [r0, #vcpu_cpsr]
        ADR     r2, __PVirt_VModeOffsets

        AND     lr, lr, #M32_bits
        LDRB    lr, [r2, lr]
        STR     sp, [r0, lr]

        AND     lr, r1, #M32_bits
        LDRB    lr, [r2, lr]
        LDR     sp, [lr, r0]!
        LDR     lr, [lr, #4]
        STRB    r1, [r0, #vcpu_cpsr]

        LDRB    r2, [r0, #vcpu_irq_pending]
        BICS    r2, r2, r1
        BLNE    call_irq
        MSR     CPSR_sf, r3
        myBX    ip


call_irq
        MOV     r2, lr
        BL      __PVirt_GetVCPU

        ; Save SP
        LDRB    r3, [r0, #vcpu_cpsr]
        AND     lr, r3, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        STR     sp, [r0, lr]

        MOV     r1, #IRQ32_mode | I32_bit
        STRB    r1, [r0, #vcpu_cpsr]
        STR     r3, [r0, #vcpu_spsr_irq]
        LDR     sp, [r0, #vcpu_r13_irq]

        ADD     lr, r2, #4
        LDR     r1, [r0, #vcpu_vectors]
        LDR     pc, [r1, #5*4]

__PVirt_VModeOffsets
        DCB     usr - init_vcpu
        DCB     fiq - init_vcpu
        DCB     irq - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu

        DCB     usr - init_vcpu
        DCB     fiq - init_vcpu
        DCB     irq - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     abt - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     und - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     usr - init_vcpu

Device_Activate
Device_Deactivate
        MOV     r0, #1
        myBX    lr

Device_Reset
Device_Sleep
        MOV     r0, #0
        myBX    lr

HAL_InitDevices
        LDR     r2, =image_start + OSROM_HALSize
        LDR     r1, [r2, #OSHdr_Entries]
        ADD     r2, r2, r1
        LDR     r3, [r2, #OS_AddDevice * 4]
        MOV     r0, #0
        ADR     r1, Device_PSR
        ADD     pc, r3, r2

        DCD     __HAL_get_env
Device_PSR
        DCW     HALDeviceType_SysPeri | HALDeviceSysPeri_PSR
        DCW     HALDeviceID_PSR_PVirt
        DCD     HALDeviceBus_Soft | HALDeviceSoftBus_Hyper
        DCD     0
        DCD     Device_PSR_Description
        %       16
        DCD     Device_Activate
        DCD     Device_Deactivate
        DCD     Device_Reset
        DCD     Device_Sleep
        DCD     -1, 0, 0, 0

        MACRO
        DE      $entry
        ASSERT  PVirt_$entry == (. - Device_PSR)
        DCD     __PVirt_$entry
        MEND

        ; Order below must match HdrSrc.hdr.CPU.PVOps
        DE      PatchCode
        DE      FastSWI
        DE      SWI

        DE      LinuxSyscall

        DE      GetCPSR
        DE      GetSPSR
        DE      LoadSaveBlock
        DE      LoadUsr
        DE      LoadUsrRegisters
        DE      MOVS_PC_LR
        DE      SetCPSR_c
        DE      SetCPSR_c_unstack
        DE      SetCPSR_cxsf
        DE      SetCPSR_cxsf_unstack
        DE      SetSPSR
        DE      StoreUsr

        DE      FindMode
        DE      GetVCPU
        DE      VModeOffsets




Device_PSR_Description
        DCB     "Linux HAL PSR Manipulation", 0
        ALIGN

        AREA    VCPU, DATA

init_vcpu
        %       8       ; Reserved for ELF thread local variables.
        DCD     test_vectors
        DCB     0
        DCB     SVC32_mode
        ALIGN
svc     %       12
usr     DCD     test_stack, USR32_mode, 0
irq     DCD     test_stack, IRQ32_mode, 0
fiq     DCD     test_stack, FIQ32_mode, 0
und     DCD     test_stack, UND32_mode, 0
abt     DCD     test_stack, ABT32_mode, 0
        %       4

        AREA    Init_Stack, DATA, NOINIT
        %       64
test_stack



        END
