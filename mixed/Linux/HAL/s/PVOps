;
; Copyright (c) 2013, 2017, Timothy Baldwin
; All rights reserved.
;
; Redistribution and use in source and binary forms, with or without
; modification, are permitted provided that the following conditions are met:
;     * Redistributions of source code must retain the above copyright
;       notice, this list of conditions and the following disclaimer.
;     * Redistributions in binary form must reproduce the above copyright
;       notice, this list of conditions and the following disclaimer in the
;       documentation and/or other materials provided with the distribution.
;     * Neither the name of RISC OS Open Ltd nor the names of its contributors
;       may be used to endorse or promote products derived from this software
;       without specific prior written permission.
;
; THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
; IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
; ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
; LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
; SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
; INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
; CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
; ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
; POSSIBILITY OF SUCH DAMAGE.
;

        GET     Hdr:ListOpts
        GET     Hdr:Macros
        GET     Hdr:System
        GET     Hdr:Machine.<Machine>
        GET     Hdr:LinuxSyscalls

        EXPORT  __PVirt_FastSWI
        EXPORT  __PVirt_FindMode
        EXPORT  __PVirt_GetCPSR
        EXPORT  __PVirt_GetSPSR
        EXPORT  __PVirt_GetVCPU
        EXPORT  __PVirt_LoadUsrRegisters
        EXPORT  __PVirt_MOVS_PC_LR
        EXPORT  __PVirt_SWI
        EXPORT  __PVirt_SetCPSR_c
        EXPORT  __PVirt_SetCPSR_cf
        EXPORT  __PVirt_SetCPSR_cs
        EXPORT  __PVirt_SetCPSR_csf
        EXPORT  __PVirt_SetCPSR_cx
        EXPORT  __PVirt_SetCPSR_cxf
        EXPORT  __PVirt_SetCPSR_cxs
        EXPORT  __PVirt_SetCPSR_cxsf
        EXPORT  __PVirt_SetSPSR
        EXPORT  __PVirt_VModeOffsets

        EXPORT  SetCPSR_End
        EXPORT  SetCPSR_Restart
        EXPORT  SetCPSR_Start

        EXPORT  SWI_handler
        EXPORT  call_irq
        EXPORT  init_vcpu
        EXPORT  test_stack
        IMPORT  test_vectors

PVirt   SETA    PVSys

        AREA    ASM, CODE, READONLY

__PVirt_GetCPSR
        STR     lr, [sp, #-4]!
        BL      __PVirt_GetVCPU
        LDRB    lr, [r0, #vcpu_cpsr]
        MRS     r0, CPSR
        BIC     r0, r0, #0xFF ; ARMv7 says the privileged bits are UNKNOWN.
        ORR     r0, r0, lr
        LDR     pc, [sp], #4

__PVirt_FindMode
        STR     lr, [sp, #-4]!
        BL      __PVirt_GetVCPU
        LDRB    lr, [r0, #vcpu_cpsr]
        AND     lr, lr, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        ADD     r0, r0, lr
        LDR     pc, [sp], #4

__PVirt_SetSPSR
        STMFD   sp!, {r0, lr}
        BL      __PVirt_FindMode
        STR     r1, [r0, #8]
        LDMFD   sp!, {r0, lr}

__PVirt_GetSPSR
        STR     lr, [sp, #-4]!
        BL      __PVirt_FindMode
        LDR     r0, [r0, #8]
        LDR     pc, [sp], #4

__PVirt_GetVCPU
        LDR     pc, =0xFFFF0FE0

SetCPSR_Start

SWI_handler
        ; Entry r2 = pointer to struct struct ucontext
        ; which is safe until sp is loaded
        MOV     lr, pc
        LDR     pc, =0xFFFF0FE0
        LDRB    r6, [r0, #vcpu_cpsr]
        AND     lr, r6, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        ADD     lr, lr, r0

        ADD     r3, r2, #struct_ucontext_registers + 12 * 4
        LDMIA   r3, {r2, r4, r5, r7, r8}
        STMIA   lr, {r4, r5}

        BIC     r8, r8, #0xFF
        ORR     r8, r8, r6
        STR     r8, [r0, #vcpu_spsr_svc]

        MOV     lr, r7
        LDR     r12, [r0, #vcpu_r13_svc]

        ; Save CPSR
        MOV     r1, #SVC32_mode + I32_bit
        STRB    r1, [r0, #vcpu_cpsr]

        ; Return PC = SVC vector
        LDR     r1, [r0, #vcpu_vectors]
        LDR     r4, [r1, #4]
        STMFD   r12!, {r2, r4}

        ; Load registers
        SUB     r3, r3, #12 * 4
        LDMIA   r3, {r0-r11}
        MOV     sp, r12
        LDMFD   sp!, {r12, pc}

__PVirt_FastSWI
        STMDB   sp!, {r0-r3, lr}
__PVirt_SWI
        ADD     r1, sp, #5*4  ; R1 = caller SP
        LDR     r2, [r1, #-4] ; R2 = caller LR
        ADD     r3, lr, #4
        BL      __PVirt_GetVCPU

        ; Save LR and SP
        LDRB    lr, [r0, #vcpu_cpsr]
        AND     lr, lr, #M32_bits
        ADD     lr, lr, #__PVirt_VModeOffsets - . - 12
        LDRB    lr, [pc, lr]
        ADD     lr, r0, lr
        STMIA   lr, {r1-r2}

        ; Save SPSR
        LDRB    lr, [r0, #vcpu_cpsr]
        MRS     r2, CPSR
        BIC     r2, r2, #0xFF ; ARMv7 says the privileged bits are UNKNOWN.
        ORR     r2, r2, lr
        STR     r2, [r0, #vcpu_spsr_svc]

        ; Save CPSR
        MOV     r2, #SVC32_mode + I32_bit
        STRB    r2, [r0, #vcpu_cpsr]

        ; Return PC = SVC vector
        LDR     r2, [r0, #vcpu_vectors]
        LDR     r2, [r2, #4]
        STR     r2, [r1, #-4]

        ; Load LR and SP
        LDR     sp, [r0, #vcpu_r13_svc]
        MOV     lr, r3

        LDMDB   r1, {r0-r3, pc}


__PVirt_LoadUsrRegisters
        ; r1 = pointer to new values of r0-r12,r13_usr,r14_usr,pc
        ; r2 = new calling mode sp
        ; r3 = new CPSR
        MOV     r9, lr
        BL      __PVirt_GetVCPU
        LDRB    r4, [r0, #vcpu_cpsr]
        AND     r4, r4, #M32_bits
        ADD     r4, r4, #__PVirt_VModeOffsets - . - 12
        LDRB    r4, [pc, r4]
        STR     r2, [r4, r0]! ; Save calling SP
        STR     r9, [r4, #4]  ; Save calling LR

        ADD     r4, r1, #12*4
        LDMIA   r4, {r5, r6, r7, r8}
        STR     r6, [r0, #vcpu_r13_usr]
        STR     r7, [r0, #vcpu_r14_usr]
        MOV     r2, sp
        STMFD   sp!, {r5, r8}

        LDMIA   r1!, {r5, r6, r7, r8}
        STMFD   sp!, {r5, r6, r7, r8}

        LDMIA   r1, {r4-r11}

        AND     ip, r3, #M32_bits
        ADD     ip, ip, #__PVirt_VModeOffsets - . - 12
        LDRB    ip, [pc, ip]
        LDR     sp, [ip, r0]!
        LDR     lr, [ip, #4]

        STRB    r3, [r0, #vcpu_cpsr]
        MOV     r1, r3
        B       SetCPSR_Restart

enter_irq
        BIC     ip, r1, #M32_bits
        ORR     ip, ip, #IRQ32_mode + I32_bit
        STRB    ip, [r0, #vcpu_cpsr]

        AND     r1, r1, #0xFF
        BIC     lr, r3, #0xFF
        ORR     lr, r1, lr ; r3 = Return CPSR
        STR     lr, [r0, #vcpu_spsr_irq]

        LDR     lr, [r2, #-4] ; lr = Return PC
        ADD     lr, lr, #4
        LDR     sp, [r0, #vcpu_r13_irq]

        LDR     r1, [r0, #vcpu_vectors]
        LDR     r1, [r1, #5*4]
        STR     r1, [r2, #-4] ; Return PC = IRQ vector

        MSR     CPSR_sf, r3
        LDMDB   r2, {r0-r3, ip, pc}


__PVirt_SetCPSR_cf
__PVirt_SetCPSR_cxf
        MSR     CPSR_f, r1
        B	__PVirt_SetCPSR_c

__PVirt_SetCPSR_cs
__PVirt_SetCPSR_cxs
        MSR     CPSR_s, r1
        B	__PVirt_SetCPSR_c

__PVirt_MOVS_PC_LR
        STMFD   sp!, {r0-r3, ip, lr}
        SUB     lr, lr, #4
        pvMRS   r1, SPSR
__PVirt_SetCPSR_csf
__PVirt_SetCPSR_cxsf
        MSR     CPSR_sf, r1
__PVirt_SetCPSR_c
__PVirt_SetCPSR_cx
        ;   In: r1 = new CPSR_c value
        ;       lr = return address
        ;       sp = stack from STMFD sp!, {r0-r3, ip, lr}
        ;
        ; Temp: r0 = Pointer to vcpu struct
        ;       r2 = SP on entry
        ;       r3 = saved CPSR_sf value
        ;       ip = temp register

        MRS     r3, CPSR
        ADD     ip, lr, #4      ; Adjust return address to avoid MSR CPSR_c
        BL      __PVirt_GetVCPU
        LDR     lr, [sp, #5*4]  ; Read callers LR
        STR     ip, [sp, #5*4]  ; Put old PC in it's place


        LDRB    r2, [r0, #vcpu_cpsr]
        AND     ip, r2, #M32_bits
        TEQ     ip, #USR32_mode
        MOVEQ   r1, r2 ; In USR mode, so do nothing

        ADR     r2, __PVirt_VModeOffsets

        LDRB    ip, [r2, ip]
        ADD     sp, sp, #6*4
        STR     sp, [ip, r0]!
        STR     lr, [ip, #4]

        AND     ip, r1, #M32_bits
        LDRB    ip, [r2, ip]
        MOV     r2, sp
        LDR     sp, [ip, r0]!
        LDR     lr, [ip, #4]
        STRB    r1, [r0, #vcpu_cpsr]

SetCPSR_Restart
        LDRB    ip, [r0, #vcpu_irq_pending]
        BICS    ip, ip, r1
        BNE     enter_irq
        MSR     CPSR_sf, r3
SetCPSR_End
        LDMDB   r2, {r0-r3, ip, pc}


call_irq
        STMFD   sp!, {r0-r3, ip, lr}
        SUB     lr, lr, #4
        LDR     r1, [r0, #vcpu_cpsr]
        B       __PVirt_SetCPSR_c

__PVirt_VModeOffsets
        DCB     usr - init_vcpu
        DCB     fiq - init_vcpu
        DCB     irq - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu

        DCB     usr - init_vcpu
        DCB     fiq - init_vcpu
        DCB     irq - init_vcpu
        DCB     svc - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     abt - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     und - init_vcpu

        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     svc - init_vcpu
        DCB     usr - init_vcpu

        AREA    VCPU, DATA

init_vcpu
        %       8       ; Reserved for ELF thread local variables.
        DCD     test_vectors
        DCB     0
        DCB     SVC32_mode
        ALIGN
svc     %       12
usr     DCD     test_stack, USR32_mode, 0
irq     DCD     test_stack, IRQ32_mode, 0
fiq     DCD     test_stack, FIQ32_mode, 0
und     DCD     test_stack, UND32_mode, 0
abt     DCD     test_stack, ABT32_mode, 0
        %       4

        AREA    Init_Stack, DATA, NOINIT
        %       64
test_stack



        END
